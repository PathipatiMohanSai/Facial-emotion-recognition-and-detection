import cv2  # OpenCV for face detection and video feed
from fer import FER  # Pre-trained emotion recognition model
import numpy as np

# Initialize the webcam feed
cap = cv2.VideoCapture(0)  # 0 means default webcam, change if multiple cameras exist

# Initialize the FER model
emotion_detector = FER()

# Start the webcam loop
while True:
    # Capture frame-by-frame
    ret, frame = cap.read()

    if not ret:
        print("Failed to grab frame")
        break

    # Resize the frame to a smaller size for faster processing
    resized_frame = cv2.resize(frame, (640, 480))

    # Detect emotions on the frame
    emotions = emotion_detector.detect_emotions(resized_frame)

    # Loop through detected faces and their emotions
    for face in emotions:
        # Get the bounding box and emotions dictionary
        box = face["box"]
        emotion = face["emotions"]

        # Extract face coordinates
        (x, y, w, h) = box

        # Draw a rectangle around the face
        cv2.rectangle(resized_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)

        # Find the emotion with the highest score
        dominant_emotion = max(emotion, key=emotion.get)
        confidence = emotion[dominant_emotion]

        # Display the dominant emotion on the frame
        text = f"{dominant_emotion}: {confidence:.2f}"
        cv2.putText(resized_frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)

    # Display the frame with emotion detection
    cv2.imshow('Emotion Recognition', resized_frame)

    # Break the loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the webcam and close all windows
cap.release()
cv2.destroyAllWindows()
